{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import operator\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from matplotlib_venn import venn2, venn2_circles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***https://twitter.com/vitorliu_55***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Narcos'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quanto a classificação da tabela de treinamento, optamos por utilizar as siglas \"b\" e \"n\" para indicar tweets bons e neutros\n",
    "#para a análise.\n",
    "\n",
    "df = pd.DataFrame(pd.read_excel(\"Narcos.xlsx\"))\n",
    "\n",
    "#remoção dos caracteres indesejados:\n",
    "df.Treinamento = df.Treinamento.replace('-','')\n",
    "df.Treinamento = df.Treinamento.replace('+','')\n",
    "df.Treinamento = df.Treinamento.replace('/','')\n",
    "df.Treinamento = df.Treinamento.replace('_','')\n",
    "df.Treinamento = df.Treinamento.replace('.','')\n",
    "df.Treinamento = df.Treinamento.replace(',','')\n",
    "df.Treinamento = df.Treinamento.replace('  ','')\n",
    "df.Treinamento = df.Treinamento.replace('!','')\n",
    "df.Treinamento = df.Treinamento.replace('@','')\n",
    "df.Treinamento = df.Treinamento.replace('#','')\n",
    "df.Treinamento = df.Treinamento.replace('$','')\n",
    "df.Treinamento = df.Treinamento.replace('%','')\n",
    "df.Treinamento = df.Treinamento.replace('^','')\n",
    "df.Treinamento = df.Treinamento.replace('&','')\n",
    "df.Treinamento = df.Treinamento.replace('*','')\n",
    "df.Treinamento = df.Treinamento.replace('(','')\n",
    "df.Treinamento = df.Treinamento.replace(')','')\n",
    "df.Treinamento = df.Treinamento.replace(':','')\n",
    "df.Treinamento = df.Treinamento.replace(';','')\n",
    "df.Treinamento = df.Treinamento.replace('\\n','')\n",
    "\n",
    "#separação dos tweets classificados como bons e neutros\n",
    "bom = df[df.Classificacao == 'b']\n",
    "neutro = df[df.Classificacao == 'n']\n",
    "\n",
    "#lista das palavras de todos os tweets:\n",
    "l_bom = np.sum(bom.Treinamento+'').split()\n",
    "l_neutro = np.sum(neutro.Treinamento+'').split()\n",
    "\n",
    "#número de palavras relevantes e irrelevantes:\n",
    "n_bom = len(l_bom)\n",
    "n_neutro = len(l_neutro)\n",
    "\n",
    "#função que aplica o teorema de bayes a um tweet específico\n",
    "def B(tweet):\n",
    "    tweet = tweet.split(\" \")\n",
    "    #probabilidade de relevância:\n",
    "    P_bom = []\n",
    "    P_neutro = []\n",
    "    \n",
    "    for palavra in range(len(tweet)):\n",
    "        P_bom.append(l_bom.count((tweet[palavra]))/(n_bom))\n",
    "        P_neutro.append(l_neutro.count((tweet[palavra]))/(n_neutro))\n",
    "    \n",
    "    total_bom = np.sum(P_bom)\n",
    "    total_neutro = np.sum(P_neutro)\n",
    "    \n",
    "    if total_bom > total_neutro:\n",
    "        return \"b\"\n",
    "    else:\n",
    "        return \"n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\jorge\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificacao</th>\n",
       "      <th>Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>vamo #masterchefbr quero assistir narcos jdndjd</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>vou começar a última temporada de narcos agora</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>rt @mqdesigns13: playeras de #pabloescobar #pl...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tô quase terminado narcos mas não quero que acabe</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>focado no objetivo da noite\\n\\nterminar a temp...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste Classificacao Bayes\n",
       "195    vamo #masterchefbr quero assistir narcos jdndjd             n     b\n",
       "196     vou começar a última temporada de narcos agora             b     b\n",
       "197  rt @mqdesigns13: playeras de #pabloescobar #pl...             n     n\n",
       "198  tô quase terminado narcos mas não quero que acabe             b     b\n",
       "199  focado no objetivo da noite\\n\\nterminar a temp...             b     b"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Narcos.xlsx', sheetname = 'Teste')\n",
    "df['Bayes'] = pd.Series()\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    bayes = B(df.Teste[i])\n",
    "    df.Bayes[i] = bayes\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porcentagem de Verdadeiros Bons: 57.5\n",
      "porcentagem de Falsos Bons: 29.5\n",
      "porcentagens de Verdadeiros Neutros: 10.5\n",
      "porcentagem de Falsos Neutros: 2.5\n"
     ]
    }
   ],
   "source": [
    "lista = []\n",
    "\n",
    "for i in range(len(df.Teste)):\n",
    "    if df.Classificacao[i] == 'b':\n",
    "        if df.Bayes[i] == 'b':\n",
    "            lista.append(1)\n",
    "        if df.Bayes[i] == 'n':\n",
    "            lista.append(2)\n",
    "    elif df.Classificacao[i] == 'n':\n",
    "        if df.Bayes[i] == 'b':\n",
    "            lista.append(3)\n",
    "        if df.Bayes[i] == 'n':\n",
    "            lista.append(4)\n",
    "\n",
    "#número de \"bons\" e \"neutros\" de acordo com a classificação manual dos tweets\n",
    "b = 120\n",
    "n = 80\n",
    "            \n",
    "VB = lista.count(1)\n",
    "FB = lista.count(3)\n",
    "VN = lista.count(4)\n",
    "FN = lista.count(2)\n",
    "\n",
    "print('porcentagem de Verdadeiros Bons: {}'.format(VB/2))\n",
    "print('porcentagem de Falsos Bons: {}'.format(FB/2))\n",
    "print('porcentagens de Verdadeiros Neutros: {}'.format(VN/2))\n",
    "print('porcentagem de Falsos Neutros: {}'.format(FN/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    Feita a verificação de performance, pode-se dizer que o analisador de sentimentos em questão é eficiente, na medida que condiz com a classificação de teste com cerca de 68% de precisão. Isso comprova que o modelo proposto por Bayes é eficaz quando se trata da análise do sentimento que uma palavra isolada carrega dentre suas diversas aplicações. Porém, o mesmo apresenta erros de precisão (falsos positivos e negativos) que prejudicam a análise e são decorrentes da enorme complexidade que compõe a linguagem, assim como casos de ironia no qual uma palavra considerada positiva é usada com sentido oposto, ou mesmo abreviações derivadas do meio da coleta dos dados. Quanto a mensagens com dupla negação e sarcasmo, o classificador não é capaz de tratá-las como incidentes isolados, pois sua maneira de comparação depende da maioria das vezes em que essa palavra foi empregada e acaba por atribuir um valor incorreto à relevância de certas palavras que compõem o tweet, dificultando sua interpretação.\n",
    "    Como expansão do projeto, seria interessante adicionar um incremento no tamanho da base de dados a precisão tende a aumentar, sendo que o modelo é baseado puramente em probabilidades calculadas pelo Teorema de Bayes e a maior amostragem significaria uma projeção mais precisa da chance de certa palavra ser considerada boa, neutra ou negativa para a análise do tweet como um todo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
